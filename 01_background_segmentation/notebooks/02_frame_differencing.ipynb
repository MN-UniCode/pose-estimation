{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc67e7-5728-4d9e-9b08-315f214b2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e01b9-b70a-42cf-86f9-13bb656eaa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing background subtraction\n",
    "def frame_differencing(prev_frame, curr_frame, threshold_value=30):\n",
    "    \n",
    "    # Conversion from color to grayscale\n",
    "    if len(prev_frame.shape) == 3:\n",
    "        gray_prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    if len(curr_frame.shape) == 3:\n",
    "        gray_curr_frame = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Computing the absolute difference between the current frame and the previous frame\n",
    "    diff = cv2.absdiff(gray_prev_frame, gray_curr_frame)\n",
    "    \n",
    "    # Applying the threshold to the difference image\n",
    "    _, thresh = cv2.threshold(diff, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return diff, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0d272-0be5-4e32-a2ea-5783390249b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def stack_images_horizontal(images, scale=1.0):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        if len(img.shape) == 2:  # grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        img = cv2.resize(img, None, fx=scale, fy=scale)\n",
    "        resized_images.append(img)\n",
    "    return cv2.hconcat(resized_images)\n",
    "\n",
    "def stack_images_vertical(images, scale=1.0):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        if len(img.shape) == 2:  # grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        img = cv2.resize(img, None, fx=scale, fy=scale)\n",
    "        resized_images.append(img)\n",
    "    return cv2.vconcat(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff973f-09f1-492e-936c-d95fa8a371a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "base_path = \"C:\\\\Users\\\\gualt\\\\OneDrive - unige.it\\\\work\\\\education\\\\courses\\\\multimodal_systems\\\\2025-2026\\\\practice_works\\\\\"\n",
    "video_path = \"movement\\\\01_background_segmentation\\\\videos\\\\\"\n",
    "video_name = \"micro-dance.avi\"\n",
    "live_input = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f333e92-58de-4d96-9888-6b6b0f5b9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 30\n",
    "\n",
    "# Selecting the input source (either a file or a video camera)\n",
    "if not live_input:\n",
    "    path = base_path + video_path + video_name\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    print(f\"Processing file: {path}.\")\n",
    "else:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"Processing webcam input.\")\n",
    "\n",
    "# Checking for possible errors\n",
    "if not cap.isOpened():\n",
    "    print(\"Error in opening the video stream.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Creating the interface for the user\n",
    "print(\"Press 'q' to quit the program.\")\n",
    "cv2.namedWindow(\"Frame differencing\")\n",
    "cv2.createTrackbar(\"Threshold\", \"Frame differencing\", threshold_value, 255, nothing)\n",
    "\n",
    "# Initializing previous frame to a black image\n",
    "gray_blank = np.zeros((480, 640), dtype=np.uint8)\n",
    "prev_frame = cv2.cvtColor(gray_blank, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Getting the current frame\n",
    "    ret, curr_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of the video or error in reading a frame.\")\n",
    "        break\n",
    "\n",
    "    # Resizing them\n",
    "    curr_frame = cv2.resize(curr_frame, (640, 480))\n",
    "\n",
    "    # Getting the value the user set for the threshold and applying frame differencing\n",
    "    threshold_value = cv2.getTrackbarPos(\"Threshold\", \"Frame differencing\")\n",
    "    diff, thresh = frame_differencing(prev_frame, curr_frame, threshold_value)\n",
    "\n",
    "    # Updating the previous frame\n",
    "    prev_frame = curr_frame.copy()\n",
    "\n",
    "    # Preparing visualization\n",
    "    top_row = stack_images_horizontal([prev_frame, curr_frame], scale=0.5)\n",
    "    bottom_row = stack_images_horizontal([diff, thresh], scale=0.5)\n",
    "    dashboard_img = stack_images_vertical([top_row, bottom_row])\n",
    "\n",
    "    # Showing results\n",
    "    cv2.imshow(\"Frame differencing\", dashboard_img)\n",
    "\n",
    "    # Checking input from the user to leave the application\n",
    "    key = cv2.waitKey(30) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        print(\"Quit the program.\")\n",
    "        break\n",
    "\n",
    "# Closing everything\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ms_25-26)",
   "language": "python",
   "name": "ms_25-26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
