{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfc1a5f-5bb4-4b13-9632-076bd72ba1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fc5836-08b8-49b0-b60f-0005d69a1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "centroid_trail_length = 30\n",
    "centroid_trail = deque(maxlen=centroid_trail_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d70a44-64be-4773-a080-40334e169582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def resize_centroid_trail(x):\n",
    "    global centroid_trail\n",
    "    global centroid_trail_length\n",
    "    centroid_trail_length = cv2.getTrackbarPos(\"Centroid trail length\", \"YOLOv8 Person Tracking\")\n",
    "    centroid_trail.clear()\n",
    "    centroid_trail = deque(maxlen=centroid_trail_length)\n",
    "    \n",
    "def get_centroid(mask, x1, y1, x2, y2):\n",
    "    M = cv2.moments(mask)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "        centroid = (cx, cy)\n",
    "    else:\n",
    "        centroid = ((x1 + x2) // 2, (y1 + y2) // 2)  # fallback to box center\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdca2340-4df6-4830-8077-5526f7d66dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "base_path = \"C:\\\\Users\\\\gualt\\\\OneDrive - unige.it\\\\work\\\\education\\\\courses\\\\multimodal_systems\\\\2025-2026\\\\practice_works\\\\\"\n",
    "video_path = \"movement\\\\02_motion_tracking\\\\videos\\\\\"\n",
    "video_name = \"micro-dance.avi\"\n",
    "live_input = False\n",
    "\n",
    "model = \"yolov8n-seg.pt\"\n",
    "person_class_id = 0\n",
    "confidence_threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c1a164-0e26-485c-9c8e-4823f562dea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing webcam input.\n",
      "Press 'r' to reset tracked person. Press 'q' to quit the program.\n"
     ]
    }
   ],
   "source": [
    "# Selecting the input source (either a file or a video camera)\n",
    "if not live_input:\n",
    "    path = base_path + video_path + video_name\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    print(f\"Processing file: {path}.\")\n",
    "else:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"Processing webcam input.\")\n",
    "\n",
    "# Checking for possible errors\n",
    "if not cap.isOpened():\n",
    "    print(\"Error in opening the video stream.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Creating the interface for the user\n",
    "print(\"Press 'r' to reset tracked person. Press 'q' to quit the program.\")\n",
    "cv2.namedWindow(\"YOLOv8 Person Tracking\")\n",
    "cv2.createTrackbar(\"Confidence threshold\", \"YOLOv8 Person Tracking\", int(confidence_threshold * 100), 100, nothing)\n",
    "cv2.createTrackbar(\"Centroid trail length\", \"YOLOv8 Person Tracking\", centroid_trail_length, 100, resize_centroid_trail)\n",
    "\n",
    "# Load model\n",
    "model = YOLO(model)\n",
    "tracked_id = None\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Getting the current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of the video or error in reading a frame.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO with tracking enabled\n",
    "    conf_th = cv2.getTrackbarPos(\"Confidence threshold\", \"YOLOv8 Person Tracking\")\n",
    "    results = model.track(source=frame, persist=True, conf=conf_th / 100.0, verbose=False)[0]\n",
    "\n",
    "    # Filter person class only\n",
    "    detections = []\n",
    "    results = model.track(source=frame, persist=True, conf=conf_th / 100.0, verbose=False)[0]\n",
    "\n",
    "    # Filter person class only\n",
    "    detections = []\n",
    "    if results.masks is not None and results.boxes is not None:\n",
    "        masks = results.masks.data.cpu().numpy().astype(np.uint8)\n",
    "        boxes = results.boxes\n",
    "        classes = boxes.cls.cpu().numpy().astype(int)\n",
    "        ids = boxes.id\n",
    "        confs = boxes.conf.cpu().numpy()\n",
    "        \n",
    "        for i, (cls, conf) in enumerate(zip(classes, confs)):\n",
    "            if cls == person_class_id:\n",
    "                if ids[i] is not None:\n",
    "                    track_id = int(ids[i].item()) if ids is not None else -1\n",
    "                    x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "                    mask = masks[i]\n",
    "                    mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "                    binary_mask = (mask_resized > 0.5).astype(np.uint8)\n",
    "                    centroid = get_centroid(mask_resized , x1, y1, x2, y2)\n",
    "                    detections.append({\n",
    "                        'track_id': track_id,\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'conf': float(conf),\n",
    "                        'centroid': centroid\n",
    "                    })\n",
    "\n",
    "    # If we don't have a person selected yet, pick the one with the lowest track_id\n",
    "    if tracked_id is None and detections:\n",
    "        tracked_id = min(d['track_id'] for d in detections)\n",
    "\n",
    "    # Find the currently tracked person\n",
    "    current_person = None\n",
    "    for d in detections:\n",
    "        if d['track_id'] == tracked_id:\n",
    "            current_person = d\n",
    "            break\n",
    "\n",
    "    if current_person:\n",
    "        x1, y1, x2, y2 = current_person['bbox']\n",
    "        cx, cy = current_person['centroid']\n",
    "        conf = current_person['conf']\n",
    "\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw centroid\n",
    "        cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "        \n",
    "        # Draw labels\n",
    "        cv2.putText(frame, f\"Person ID {tracked_id} Conf {conf:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Centroid: ({cx},{cy})\", (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "\n",
    "        # Update trail\n",
    "        centroid_trail.appendleft((cx, cy))\n",
    "\n",
    "        # Draw trail\n",
    "        for i in range(1, len(centroid_trail)):\n",
    "            pt1 = centroid_trail[i - 1]\n",
    "            pt2 = centroid_trail[i]\n",
    "            cv2.line(frame, pt1, pt2, (0, 150, 255), 2)\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow(\"YOLOv8 Person Tracking\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('r'):\n",
    "        print(\"Reset tracking.\")\n",
    "        tracked_id = None\n",
    "        centroid_trail.clear()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5d4b2-653a-4d35-9167-cbbcfb505538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ms_25-26)",
   "language": "python",
   "name": "ms_25-26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
